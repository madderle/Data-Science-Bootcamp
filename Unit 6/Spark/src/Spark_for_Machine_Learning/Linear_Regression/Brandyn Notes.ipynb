{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lrex').getOrCreate()\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+\n",
      "|              label|            features|\n",
      "+-------------------+--------------------+\n",
      "| -9.490009878824548|(10,[0,1,2,3,4,5,...|\n",
      "| 0.2577820163584905|(10,[0,1,2,3,4,5,...|\n",
      "| -4.438869807456516|(10,[0,1,2,3,4,5,...|\n",
      "|-19.782762789614537|(10,[0,1,2,3,4,5,...|\n",
      "| -7.966593841555266|(10,[0,1,2,3,4,5,...|\n",
      "| -7.896274316726144|(10,[0,1,2,3,4,5,...|\n",
      "| -8.464803554195287|(10,[0,1,2,3,4,5,...|\n",
      "| 2.1214592666251364|(10,[0,1,2,3,4,5,...|\n",
      "| 1.0720117616524107|(10,[0,1,2,3,4,5,...|\n",
      "|-13.772441561702871|(10,[0,1,2,3,4,5,...|\n",
      "| -5.082010756207233|(10,[0,1,2,3,4,5,...|\n",
      "|  7.887786536531237|(10,[0,1,2,3,4,5,...|\n",
      "| 14.323146365332388|(10,[0,1,2,3,4,5,...|\n",
      "|-20.057482615789212|(10,[0,1,2,3,4,5,...|\n",
      "|-0.8995693247765151|(10,[0,1,2,3,4,5,...|\n",
      "| -19.16829262296376|(10,[0,1,2,3,4,5,...|\n",
      "|  5.601801561245534|(10,[0,1,2,3,4,5,...|\n",
      "|-3.2256352187273354|(10,[0,1,2,3,4,5,...|\n",
      "| 1.5299675726687754|(10,[0,1,2,3,4,5,...|\n",
      "| -0.250102447941961|(10,[0,1,2,3,4,5,...|\n",
      "+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bring in training data. Notice there is a single features column thats a vector and have to transform the data.\n",
    "training = spark.read.format('libsvm').load('sample_linear_regression_data.txt')\n",
    "training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "lr = LinearRegression(featuresCol='features',labelCol='label',predictionCol='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.0073, 0.8314, -0.8095, 2.4412, 0.5192, 1.1535, -0.2989, -0.5129, -0.6197, 0.6956])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the training summary\n",
    "training_summary = lrModel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027839179518600154"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can look at r2 or rootmeansqared or most things off of this.\n",
    "training_summary.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should split the data into test train split. Or can do k fold\n",
    "all_data = spark.read.format('libsvm').load('sample_linear_regression_data.txt')\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = all_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new model off of training data\n",
    "correct_moel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = correct_moel.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.540321503037012"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.rootMeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unlabled dataset\n",
    "unlabeled_data = test_data.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|            features|         prediction|\n",
      "+--------------------+-------------------+\n",
      "|(10,[0,1,2,3,4,5,...| 1.7453403705148338|\n",
      "|(10,[0,1,2,3,4,5,...|-0.8560096539539437|\n",
      "|(10,[0,1,2,3,4,5,...| 3.4227229801686865|\n",
      "|(10,[0,1,2,3,4,5,...| -2.740473093972807|\n",
      "|(10,[0,1,2,3,4,5,...| 0.6817412011388044|\n",
      "|(10,[0,1,2,3,4,5,...| 0.7781077626085546|\n",
      "|(10,[0,1,2,3,4,5,...| 1.9172997025445278|\n",
      "|(10,[0,1,2,3,4,5,...|  2.236918868494073|\n",
      "|(10,[0,1,2,3,4,5,...|-2.6813211283771112|\n",
      "|(10,[0,1,2,3,4,5,...|  2.200067856312657|\n",
      "|(10,[0,1,2,3,4,5,...| 0.2867728607591444|\n",
      "|(10,[0,1,2,3,4,5,...| 0.8978991128456428|\n",
      "|(10,[0,1,2,3,4,5,...|  1.161588947117569|\n",
      "|(10,[0,1,2,3,4,5,...| 0.6816111340708761|\n",
      "|(10,[0,1,2,3,4,5,...| -1.539230812445407|\n",
      "|(10,[0,1,2,3,4,5,...|  1.280003408248381|\n",
      "|(10,[0,1,2,3,4,5,...|-0.7005282978513427|\n",
      "|(10,[0,1,2,3,4,5,...| -0.721002972935624|\n",
      "|(10,[0,1,2,3,4,5,...|-1.2946876967803405|\n",
      "|(10,[0,1,2,3,4,5,...| -4.965126275108953|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Do the predictions by calling the transform\n",
    "predictions = correct_moel.transform(unlabeled_data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E-Commerce Code Along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Initialize #####################\n",
    "\n",
    "# Import Spark and Create Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('lr_example').getOrCreate()\n",
    "\n",
    "# Import Model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Email',\n",
       " 'Address',\n",
       " 'Avatar',\n",
       " 'Avg Session Length',\n",
       " 'Time on App',\n",
       " 'Time on Website',\n",
       " 'Length of Membership',\n",
       " 'Yearly Amount Spent']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################ Data ############################\n",
    "# Read CSV\n",
    "data = spark.read.csv(\"Ecommerce_Customers.csv\",inferSchema=True,header=True)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the assembler\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Avg Session Length\", \"Time on App\", \n",
    "               \"Time on Website\",'Length of Membership'],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to transform that data and add new column called feautres\n",
    "output = assembler.transform(data)\n",
    "\n",
    "# Select the features and the column going to predict\n",
    "final_data = output.select(\"features\",'Yearly Amount Spent')\n",
    "\n",
    "# Split the data\n",
    "train_data,test_data = final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [25.4870332126,38.919631539,0.300544880775,61.7069946791] Intercept: -1041.2923689106005\n"
     ]
    }
   ],
   "source": [
    "################### Model ##########################\n",
    "# Create a Linear Regression Model object\n",
    "lr = LinearRegression(labelCol='Yearly Amount Spent')\n",
    "\n",
    "# Fit the model to the data and call this model lrModel\n",
    "lrModel = lr.fit(train_data,)\n",
    "\n",
    "# Print the coefficients and intercept for linear regression\n",
    "print(\"Coefficients: {} Intercept: {}\".format(lrModel.coefficients,lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 9.467089403089085\n",
      "MSE: 89.62578176608164\n"
     ]
    }
   ],
   "source": [
    "test_results = lrModel.evaluate(test_data)\n",
    "print(\"RMSE: {}\".format(test_results.rootMeanSquaredError))\n",
    "print(\"MSE: {}\".format(test_results.meanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984497274717527"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To perform predictions\n",
    "\n",
    "# Create unlabeled data or get unlabeled data\n",
    "unlabeled_data = test_data.select('features')\n",
    "\n",
    "# Do predictions\n",
    "predictions = lrModel.transform(unlabeled_data)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
